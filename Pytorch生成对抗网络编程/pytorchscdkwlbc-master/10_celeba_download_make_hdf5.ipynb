{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DpII-qgno6EX"
      },
      "source": [
        "# Human Faces - Download CelebA Data and Make HDF5\n",
        "\n",
        "Make Your First GAN With PyTorch, 2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B6g6LPI9Xjgl"
      },
      "outputs": [],
      "source": [
        "# # mount Drive to access data files\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('./mount')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wi65ho8_tgQG"
      },
      "source": [
        "## Download CelebA Dataset\n",
        "\n",
        "The downloaded data will be deleted after the colab virtual machine is deleted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jw2Il5l-zB1l"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "-MKGmYJW1EPY",
        "outputId": "a7d96fb7-8670-4dd9-f949-e31d424246bf"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mf:\\File\\书籍\\人工智能\\Pytorch生成对抗网络编程\\pytorchscdkwlbc-master\\10_celeba_download_make_hdf5.ipynb 单元格 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/File/%E4%B9%A6%E7%B1%8D/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/pytorchscdkwlbc-master/10_celeba_download_make_hdf5.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# download data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/File/%E4%B9%A6%E7%B1%8D/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Pytorch%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/pytorchscdkwlbc-master/10_celeba_download_make_hdf5.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mnist_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mCelebA(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../celeba_data/\u001b[39;49m\u001b[39m'\u001b[39;49m, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mf:\\Software\\PL_SDK\\Python\\Anacnoda\\envs\\d2l\\lib\\site-packages\\torchvision\\datasets\\celeba.py:80\u001b[0m, in \u001b[0;36mCelebA.__init__\u001b[1;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtarget_transform is specified but target_type is empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity():\n\u001b[0;32m     83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mf:\\Software\\PL_SDK\\Python\\Anacnoda\\envs\\d2l\\lib\\site-packages\\torchvision\\datasets\\celeba.py:150\u001b[0m, in \u001b[0;36mCelebA.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m (file_id, md5, filename) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_list:\n\u001b[1;32m--> 150\u001b[0m     download_file_from_google_drive(file_id, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_folder), filename, md5)\n\u001b[0;32m    152\u001b[0m extract_archive(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_folder, \u001b[39m\"\u001b[39m\u001b[39mimg_align_celeba.zip\u001b[39m\u001b[39m\"\u001b[39m))\n",
            "File \u001b[1;32mf:\\Software\\PL_SDK\\Python\\Anacnoda\\envs\\d2l\\lib\\site-packages\\torchvision\\datasets\\utils.py:259\u001b[0m, in \u001b[0;36mdownload_file_from_google_drive\u001b[1;34m(file_id, root, filename, md5)\u001b[0m\n\u001b[0;32m    256\u001b[0m         api_response, content \u001b[39m=\u001b[39m _extract_gdrive_api_response(response)\n\u001b[0;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m api_response \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mQuota exceeded\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    260\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe daily quota of the file \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m is exceeded and it \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be downloaded. This is a limitation of Google Drive \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand can only be overcome by trying again later.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m         )\n\u001b[0;32m    265\u001b[0m     _save_response_content(content, fpath)\n\u001b[0;32m    267\u001b[0m \u001b[39m# In case we deal with an unhandled GDrive API response, the file should be smaller than 10kB and contain only text\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later."
          ]
        }
      ],
      "source": [
        "# download data\n",
        "\n",
        "mnist_dataset = torchvision.datasets.CelebA(root='../celeba_data/', download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B9hyVvblv0kF"
      },
      "source": [
        "## Extract Images and Re-Package as HDF5\n",
        "\n",
        "The HDF5 file is located in google Drive and won't be deleted when the colab virtual machine is deleted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mgPN34s04_li"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import zipfile\n",
        "import imageio\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "colab_type": "code",
        "id": "UJXhnB3wv7kl",
        "outputId": "4131f301-1c89-4b21-a9e5-3eb2aff267f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<timed exec>:16: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images done ..  1000\n",
            "images done ..  2000\n",
            "images done ..  3000\n",
            "images done ..  4000\n",
            "images done ..  5000\n",
            "images done ..  6000\n",
            "images done ..  7000\n",
            "images done ..  8000\n",
            "images done ..  9000\n",
            "images done ..  10000\n",
            "images done ..  11000\n",
            "images done ..  12000\n",
            "images done ..  13000\n",
            "images done ..  14000\n",
            "images done ..  15000\n",
            "images done ..  16000\n",
            "images done ..  17000\n",
            "images done ..  18000\n",
            "images done ..  19000\n",
            "images done ..  20000\n",
            "CPU times: total: 36.8 s\n",
            "Wall time: 3min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# location of the HDF5 package, yours may be under /gan/ not /myo_gan/\n",
        "hdf5_file = '../celeba_data/celeba_aligned_small.h5py'\n",
        "\n",
        "# how many of the 202,599 images to extract and package into HDF5\n",
        "total_images = 20000\n",
        "\n",
        "with h5py.File(hdf5_file, 'w') as hf:\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    with zipfile.ZipFile('../celeba_data/img_align_celeba.zip', 'r') as zf:\n",
        "      for i in zf.namelist():\n",
        "        if (i[-4:] == '.jpg'):\n",
        "          # extract image\n",
        "          ofile = zf.extract(i)\n",
        "          img = imageio.imread(ofile)\n",
        "          os.remove(ofile)\n",
        "\n",
        "          # add image data to HDF5 file with new name\n",
        "          hf.create_dataset('img_align_celeba/'+str(count)+'.jpg', data=img, compression=\"gzip\", compression_opts=9)\n",
        "          \n",
        "          count = count + 1\n",
        "          if (count%1000 == 0):\n",
        "            print(\"images done .. \", count)\n",
        "            pass\n",
        "            \n",
        "          # stop when total_images reached\n",
        "          if (count == total_images):\n",
        "            break\n",
        "          pass\n",
        "\n",
        "        pass\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3O1cSNS2_mdC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "10_celeba_download_make_hdf5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
